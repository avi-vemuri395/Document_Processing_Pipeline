"""
Hybrid Excel Extractor - Direct pandas extraction with optional LLM enhancement.

PRODUCTION STORAGE NOTE:
------------------------
In production, extracted data would be stored as follows:
1. Raw extraction results ‚Üí S3 bucket with versioning (s3://loan-docs/extractions/{app_id}/excel/)
2. Structured JSON ‚Üí PostgreSQL/DynamoDB for querying
3. Confidence scores ‚Üí Separate metrics table for monitoring
4. LLM enhancement cache ‚Üí Redis/DynamoDB to avoid redundant API calls
5. Audit logs ‚Üí CloudWatch/Datadog for compliance tracking

For this test repository, we store everything locally in outputs/extractions/
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, Any, List, Optional, Union, Tuple
from dataclasses import dataclass
import re
import json
import time
from decimal import Decimal

# Optional LLM imports (only used when needed)
try:
    from anthropic import AsyncAnthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False


@dataclass
class HybridExcelResult:
    """Result from hybrid Excel extraction."""
    extraction_method: str  # "pandas_only", "pandas_plus_llm", "fallback_image"
    document_type: str
    confidence: float
    processing_time: float
    structured_data: Dict[str, Any]
    field_count: int
    api_cost_estimate: float
    errors: List[str]


class HybridExcelExtractor:
    """
    Hybrid Excel extractor that prioritizes direct pandas extraction.
    
    Extraction Strategy:
    1. ALWAYS use pandas first for 100% numeric accuracy
    2. Apply pattern matching for financial data structuring
    3. Use LLM ONLY when confidence < 80% for semantic mapping
    4. Fallback to image‚ÜíLLM only if pandas completely fails
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """Initialize hybrid extractor."""
        # Store API key for lazy initialization
        self.api_key = api_key
        self._llm_client = None  # Lazy initialization
        
        # Financial patterns for structured extraction
        self.patterns = self._build_patterns()
    
    @property
    def llm_client(self):
        """Lazy initialization of AsyncAnthropic client."""
        if self._llm_client is None and ANTHROPIC_AVAILABLE and self.api_key:
            self._llm_client = AsyncAnthropic(api_key=self.api_key)
        return self._llm_client
    
    def _build_patterns(self) -> Dict[str, List[re.Pattern]]:
        """Build comprehensive financial patterns."""
        return {
            'assets': [
                re.compile(r'\b(cash|checking|savings|investments?|stocks?|bonds?|real\s*estate)\b', re.I),
                re.compile(r'\b(accounts?\s*receivable|inventory|equipment|property)\b', re.I),
            ],
            'liabilities': [
                re.compile(r'\b(loans?|debt|mortgages?|payable|credit\s*cards?|lines?\s*of\s*credit)\b', re.I),
                re.compile(r'\b(current\s*liabilities|long[\s-]*term\s*debt)\b', re.I),
            ],
            'revenue': [
                re.compile(r'\b(revenue|sales|income|receipts|earnings)\b', re.I),
                re.compile(r'\b(gross\s*sales|net\s*sales|service\s*revenue)\b', re.I),
            ],
            'expenses': [
                re.compile(r'\b(expenses?|costs?|salaries|wages|rent|utilities)\b', re.I),
                re.compile(r'\b(depreciation|interest|taxes|insurance)\b', re.I),
            ],
            'totals': [
                re.compile(r'\b(total|sum|subtotal|net|gross)\b', re.I),
            ]
        }
    
    async def extract(self, file_path: Union[str, Path]) -> HybridExcelResult:
        """
        Extract data from Excel file using hybrid approach.
        
        Args:
            file_path: Path to Excel file
            
        Returns:
            HybridExcelResult with extracted and structured data
        """
        start_time = time.time()
        file_path = Path(file_path)
        errors = []
        
        print(f"\n{'='*70}")
        print(f"üîÑ HYBRID EXCEL EXTRACTION: {file_path.name}")
        print(f"{'='*70}")
        
        # Phase 1: Direct pandas extraction (ALWAYS first)
        try:
            print("\nüìä Phase 1: Direct Pandas Extraction")
            raw_data = self._extract_with_pandas(file_path)
            
            if not raw_data or not raw_data.get('sheets'):
                raise ValueError("No data extracted from Excel file")
            
            print(f"  ‚úÖ Extracted {len(raw_data['sheets'])} sheets")
            print(f"  ‚úÖ Found {raw_data['stats']['total_numeric_values']} numeric values")
            
            # Phase 2: Pattern-based structuring
            print("\nüîç Phase 2: Pattern-Based Structuring")
            structured = self._structure_with_patterns(raw_data)
            print(f"  ‚úÖ Identified document type: {structured['document_type']}")
            print(f"  ‚úÖ Confidence: {structured['confidence']:.1%}")
            
            # Phase 3: Optional LLM enhancement (only if low confidence)
            api_cost = 0.0
            extraction_method = "pandas_only"
            
            if structured['confidence'] < 0.8 and self.llm_client:
                print("\nü§ñ Phase 3: LLM Enhancement (low confidence)")
                enhanced = await self._enhance_with_llm(structured)
                if enhanced:
                    structured['semantic_mappings'] = enhanced['mappings']
                    api_cost = enhanced.get('cost_estimate', 0.0)
                    extraction_method = "pandas_plus_llm"
                    print(f"  ‚úÖ Added semantic mappings")
                    print(f"  üí∞ API cost: ${api_cost:.4f}")
            
            processing_time = time.time() - start_time
            
            # Count extracted fields
            field_count = self._count_fields(structured['data'])
            
            print(f"\n‚úÖ EXTRACTION COMPLETE:")
            print(f"  ‚Ä¢ Method: {extraction_method}")
            print(f"  ‚Ä¢ Fields extracted: {field_count}")
            print(f"  ‚Ä¢ Processing time: {processing_time:.2f}s")
            print(f"  ‚Ä¢ Cost: ${api_cost:.4f}")
            print(f"{'='*70}\n")
            
            return HybridExcelResult(
                extraction_method=extraction_method,
                document_type=structured['document_type'],
                confidence=structured['confidence'],
                processing_time=processing_time,
                structured_data=structured['data'],
                field_count=field_count,
                api_cost_estimate=api_cost,
                errors=errors
            )
            
        except Exception as e:
            print(f"\n‚ùå Pandas extraction failed: {e}")
            errors.append(str(e))
            
            # Phase 4: Fallback to image‚ÜíLLM (last resort)
            if self.llm_client:
                print("\nüì∑ Phase 4: Fallback to Image‚ÜíLLM")
                fallback_result = await self._fallback_to_image_llm(file_path)
                
                return HybridExcelResult(
                    extraction_method="fallback_image",
                    document_type="unknown",
                    confidence=0.5,
                    processing_time=time.time() - start_time,
                    structured_data=fallback_result.get('data', {}),
                    field_count=0,
                    api_cost_estimate=0.02,
                    errors=errors
                )
            
            # Complete failure
            return HybridExcelResult(
                extraction_method="failed",
                document_type="unknown",
                confidence=0.0,
                processing_time=time.time() - start_time,
                structured_data={},
                field_count=0,
                api_cost_estimate=0.0,
                errors=errors
            )
    
    def _extract_with_pandas(self, file_path: Path) -> Dict[str, Any]:
        """Phase 1: Direct pandas extraction with 100% accuracy."""
        result = {
            'sheets': {},
            'stats': {
                'total_sheets': 0,
                'total_numeric_values': 0,
                'total_text_values': 0,
                'total_cells': 0
            }
        }
        
        # Read all sheets
        excel_file = pd.ExcelFile(file_path)
        
        for sheet_name in excel_file.sheet_names[:10]:  # Limit to 10 sheets
            try:
                # Read with and without headers to get all data
                df = pd.read_excel(file_path, sheet_name=sheet_name, header=None)
                
                if df.empty:
                    continue
                
                # Extract all data
                sheet_data = {
                    'numeric_values': [],
                    'text_values': [],
                    'shape': df.shape,
                    'has_headers': False
                }
                
                # Detect if first row is headers
                first_row = df.iloc[0] if len(df) > 0 else []
                if all(isinstance(val, str) for val in first_row.dropna()):
                    sheet_data['has_headers'] = True
                    sheet_data['headers'] = first_row.tolist()
                
                # Extract all values with their positions
                for row_idx, row in df.iterrows():
                    for col_idx, value in enumerate(row):
                        if pd.notna(value):
                            cell_info = {
                                'row': row_idx,
                                'col': col_idx,
                                'value': value
                            }
                            
                            # Parse numeric values
                            numeric_val = self._parse_numeric(value)
                            if numeric_val is not None:
                                cell_info['numeric'] = numeric_val
                                sheet_data['numeric_values'].append(cell_info)
                                result['stats']['total_numeric_values'] += 1
                            else:
                                cell_info['text'] = str(value)
                                sheet_data['text_values'].append(cell_info)
                                result['stats']['total_text_values'] += 1
                
                result['sheets'][sheet_name] = sheet_data
                result['stats']['total_sheets'] += 1
                result['stats']['total_cells'] += df.shape[0] * df.shape[1]
                
            except Exception as e:
                print(f"    ‚ö†Ô∏è Error reading sheet '{sheet_name}': {e}")
                continue
        
        return result
    
    def _structure_with_patterns(self, raw_data: Dict[str, Any]) -> Dict[str, Any]:
        """Phase 2: Apply financial patterns to structure data."""
        structured = {
            'document_type': 'unknown',
            'confidence': 0.0,
            'data': {
                'financial_data': {},
                'metadata': {}
            }
        }
        
        # Analyze each sheet
        doc_types = []
        for sheet_name, sheet_data in raw_data['sheets'].items():
            # Detect document type
            doc_type = self._detect_document_type(sheet_name, sheet_data)
            doc_types.append(doc_type)
            
            # Extract structured data based on type
            if doc_type == 'balance_sheet':
                structured['data']['financial_data']['balance_sheet'] = \
                    self._extract_balance_sheet(sheet_data)
            elif doc_type == 'income_statement':
                structured['data']['financial_data']['income_statement'] = \
                    self._extract_income_statement(sheet_data)
            else:
                # Generic extraction
                structured['data']['financial_data'][sheet_name] = \
                    self._extract_generic_financial(sheet_data)
        
        # Set primary document type
        if doc_types:
            from collections import Counter
            type_counts = Counter(doc_types)
            structured['document_type'] = type_counts.most_common(1)[0][0]
            
            # Calculate confidence based on pattern matches
            total_values = raw_data['stats']['total_numeric_values']
            if total_values > 0:
                structured['confidence'] = min(0.95, 0.5 + (total_values / 100))
        
        # Add metadata
        structured['data']['metadata'] = {
            'sheets_processed': list(raw_data['sheets'].keys()),
            'total_numeric_values': raw_data['stats']['total_numeric_values'],
            'extraction_timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        return structured
    
    def _detect_document_type(self, sheet_name: str, sheet_data: Dict[str, Any]) -> str:
        """Detect document type from sheet name and content."""
        sheet_lower = sheet_name.lower()
        
        # Check sheet name
        if any(term in sheet_lower for term in ['balance', 'bs']):
            return 'balance_sheet'
        elif any(term in sheet_lower for term in ['profit', 'loss', 'p&l', 'pl', 'income']):
            return 'income_statement'
        elif any(term in sheet_lower for term in ['cash', 'flow']):
            return 'cash_flow'
        
        # Check content
        all_text = ' '.join(item['text'] for item in sheet_data.get('text_values', []))
        all_text_lower = all_text.lower()
        
        if 'assets' in all_text_lower and 'liabilities' in all_text_lower:
            return 'balance_sheet'
        elif 'revenue' in all_text_lower or 'expenses' in all_text_lower:
            return 'income_statement'
        
        return 'generic'
    
    def _extract_balance_sheet(self, sheet_data: Dict[str, Any]) -> Dict[str, Any]:
        """Extract balance sheet specific data."""
        result = {
            'assets': {},
            'liabilities': {},
            'equity': {},
            'totals': {}
        }
        
        # Group numeric values by their text context
        for numeric_item in sheet_data.get('numeric_values', []):
            # Find nearest text label
            label = self._find_label_for_value(numeric_item, sheet_data['text_values'])
            if not label:
                continue
            
            label_lower = label.lower()
            value = numeric_item['numeric']
            
            # Categorize based on patterns
            if any(p.search(label) for p in self.patterns['assets']):
                result['assets'][label] = value
            elif any(p.search(label) for p in self.patterns['liabilities']):
                result['liabilities'][label] = value
            elif 'equity' in label_lower or 'capital' in label_lower:
                result['equity'][label] = value
            
            # Check for totals
            if any(p.search(label) for p in self.patterns['totals']):
                if 'asset' in label_lower:
                    result['totals']['total_assets'] = value
                elif 'liabilit' in label_lower:
                    result['totals']['total_liabilities'] = value
                elif 'equity' in label_lower:
                    result['totals']['total_equity'] = value
        
        return result
    
    def _extract_income_statement(self, sheet_data: Dict[str, Any]) -> Dict[str, Any]:
        """Extract income statement specific data."""
        result = {
            'revenue': {},
            'expenses': {},
            'totals': {}
        }
        
        for numeric_item in sheet_data.get('numeric_values', []):
            label = self._find_label_for_value(numeric_item, sheet_data['text_values'])
            if not label:
                continue
            
            value = numeric_item['numeric']
            
            # Categorize
            if any(p.search(label) for p in self.patterns['revenue']):
                result['revenue'][label] = value
            elif any(p.search(label) for p in self.patterns['expenses']):
                result['expenses'][label] = value
            
            # Check for totals
            if any(p.search(label) for p in self.patterns['totals']):
                label_lower = label.lower()
                if 'revenue' in label_lower or 'sales' in label_lower:
                    result['totals']['total_revenue'] = value
                elif 'expense' in label_lower or 'cost' in label_lower:
                    result['totals']['total_expenses'] = value
                elif 'income' in label_lower or 'profit' in label_lower:
                    result['totals']['net_income'] = value
        
        return result
    
    def _extract_generic_financial(self, sheet_data: Dict[str, Any]) -> Dict[str, Any]:
        """Extract generic financial data."""
        result = {}
        
        # Simply extract all numeric values with their labels
        for numeric_item in sheet_data.get('numeric_values', []):
            label = self._find_label_for_value(numeric_item, sheet_data['text_values'])
            if label:
                # Clean up the label
                clean_label = re.sub(r'[^\w\s]', '', label).strip()
                clean_label = clean_label.replace(' ', '_').lower()
                if clean_label:
                    result[clean_label] = numeric_item['numeric']
        
        return result
    
    def _find_label_for_value(self, numeric_item: Dict, text_values: List[Dict]) -> Optional[str]:
        """Find the text label for a numeric value."""
        row = numeric_item['row']
        col = numeric_item['col']
        
        # Look for label in same row (to the left)
        for text_item in text_values:
            if text_item['row'] == row and text_item['col'] < col:
                return text_item['text']
        
        # Look for label in column header
        for text_item in text_values:
            if text_item['col'] == col and text_item['row'] < row:
                return text_item['text']
        
        return None
    
    def _parse_numeric(self, value: Any) -> Optional[float]:
        """Parse numeric value with 100% accuracy."""
        if pd.isna(value):
            return None
        
        if isinstance(value, (int, float)):
            return float(value)
        
        if isinstance(value, str):
            # Remove formatting
            cleaned = re.sub(r'[$,\s]', '', value.strip())
            
            # Handle parentheses for negatives
            if '(' in cleaned and ')' in cleaned:
                cleaned = '-' + cleaned.replace('(', '').replace(')', '')
            
            # Remove percentage signs
            cleaned = cleaned.replace('%', '')
            
            try:
                return float(cleaned)
            except ValueError:
                return None
        
        return None
    
    async def _enhance_with_llm(self, structured: Dict[str, Any]) -> Dict[str, Any]:
        """Phase 3: Optional LLM enhancement for semantic mapping."""
        if not self.llm_client:
            return {}
        
        # Build concise prompt with only ambiguous fields
        prompt = f"""Map these financial field names to standard loan application fields:

{json.dumps(list(structured['data']['financial_data'].keys())[:20], indent=2)}

Return JSON mapping original names to standard fields like:
- total_assets
- total_liabilities  
- net_worth
- annual_revenue
- net_income

Only map fields you're confident about."""

        try:
            response = await self.llm_client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=1024,
                temperature=0,
                messages=[{"role": "user", "content": prompt}]
            )
            
            # Parse response
            response_text = response.content[0].text.strip()
            if '```json' in response_text:
                response_text = response_text.split('```json')[1].split('```')[0]
            
            mappings = json.loads(response_text)
            
            # Estimate cost
            cost = len(prompt) * 0.000003 / 4  # Rough estimate
            
            return {'mappings': mappings, 'cost_estimate': cost}
            
        except Exception as e:
            print(f"    ‚ö†Ô∏è LLM enhancement failed: {e}")
            return {}
    
    async def _fallback_to_image_llm(self, file_path: Path) -> Dict[str, Any]:
        """Phase 4: Fallback to image‚ÜíLLM extraction."""
        # This would use the existing UniversalPreprocessor
        # For now, return empty result
        return {
            'data': {'error': 'Image fallback not implemented'},
            'cost_estimate': 0.02
        }
    
    def _count_fields(self, data: Dict[str, Any]) -> int:
        """Recursively count all fields in the structured data."""
        count = 0
        
        def count_recursive(obj):
            nonlocal count
            if isinstance(obj, dict):
                for key, value in obj.items():
                    if value is not None and value != {} and value != []:
                        if isinstance(value, (dict, list)):
                            count_recursive(value)
                        else:
                            count += 1
            elif isinstance(obj, list):
                for item in obj:
                    count_recursive(item)
        
        count_recursive(data)
        return count